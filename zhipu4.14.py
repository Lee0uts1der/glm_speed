stream_options= dict(include_usage=True)
from zhipuai import ZhipuAI
import time

client = ZhipuAI(api_key="3c87b4c80506418a8882bef064ec2199.BaNPFlZcQHfJOFyg")

t0 = time.time()

response = client.chat.completions.create(
    model="glm-z1-airx",
    messages=[
        {"role": "user", "content": "å†™ä¸€ç¯‡è®®è®ºæ–‡ï¼Œè®ºè¿°å­¦ä¹ AIæ˜¯æœ‰å¿…è¦çš„"}
    ],
    stream=True,
    stream_options={"include_usage": True}
)

t1 = None
t3 = None
total_tokens = 0
all_content = ""

for chunk in response:
    if not t1:
        t1 = time.time()
    print(chunk.choices[0].delta.content, end="")
    all_content += chunk.choices[0].delta.content

    # ä½¿ç”¨è¯¦æƒ…å‡ºç°åœ¨æœ€åä¸€ä¸ª chunk ä¸­
    if hasattr(chunk, "usage") and chunk.usage:
        total_tokens = chunk.usage.completion_tokens

t3 = time.time()

# è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
print("\n\nâ±ï¸ é¦– token å»¶è¿Ÿï¼ˆt1 - t0ï¼‰: {:.2f} ç§’".format(t1 - t0))
print("ğŸ“ æ–‡æœ¬ç”Ÿæˆè€—æ—¶ï¼ˆt3 - t1ï¼‰: {:.2f} ç§’".format(t3 - t1))
print("ğŸ”¢ æ€»ç”Ÿæˆ token æ•°: {}".format(total_tokens))
if total_tokens > 0:
    print("ğŸš€ å¹³å‡ç”Ÿæˆé€Ÿåº¦: {:.2f} token/s".format(total_tokens / (t3 - t1)))
